{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 데이터 작업\n",
        "\n",
        "데이터는 기계 학습 모델 작성 과정의 토대가 되는 요소라 할 수 있습니다. 전문 데이터 과학 솔루션을 빌드하려면 클라우드에서 중앙 집중식으로 데이터를 관리하고, 여러 워크스테이션과 컴퓨팅 대상에서 실험 실행 및 모델 학습을 진행하는 데이터 과학자 팀에게 해당 데이터 액세스 권한을 제공해야 합니다.\n",
        "\n",
        "이 Notebook에서는 데이터 작업을 위한 두 개의 Azure Machine Learning 개체인 *데이터 저장소* 및 *데이터 자산을 살펴봅니다*.\n",
        "\n",
        "## 시작하기 전에\n",
        "\n",
        "이 Notebook에서 코드를 실행하려면 **최신 버전의 azureml-ai-ml** 패키지가 필요합니다. 아래 셀의 명령을 실행하여 이 패키지가 설치되어 있는지 확인합니다.\n",
        "\n",
        "> **고**:\n",
        "> **azure-ai-ml** 패키지가 설치되지 않은 경우 를 실행 `pip install azure-ai-ml` 하여 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789326586
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 작업 영역에 연결\n",
        "\n",
        "필요한 SDK 패키지를 설치했으므로 작업 영역에 연결할 수 있습니다.\n",
        "\n",
        "작업 영역에 연결하려면 식별자 매개 변수(구독 ID, 리소스 그룹 이름 및 작업 영역 이름)가 필요합니다. 리소스 그룹 이름 및 작업 영역 이름이 이미 채워져 있습니다. 명령을 완료하려면 구독 ID만 필요합니다.\n",
        "\n",
        "필요한 매개 변수를 찾으려면 Studio의 오른쪽 위에 있는 구독 및 작업 영역 이름을 클릭합니다. 오른쪽에 창이 열립니다.\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> 구독 ID를 복사하고 **YOUR-SUBSCRIPTION-ID** 를 복사한 값으로 바꿉니다. </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 데이터 저장소 나열\n",
        "\n",
        "Azure Machine Learning 작업 영역을 만들면 Azure Storage 계정도 만들어집니다. 스토리지 계정에는 Blob 및 파일 스토리지가 포함되며 작업 영역과 데이터 저장소로 자동으로 연결 **됩니다**. 작업 영역에 연결된 모든 데이터 저장소를 나열할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789343369
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "`workspaceblobstore` 앞에서 탐색한 **azureml-blobstore-...** 컨테이너에 연결하는 를 확인합니다. 는 `workspacefilestore` **코드-...** 파일 공유에 연결합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 데이터 저장소 만들기\n",
        "\n",
        "다른 Azure Storage 서비스를 Azure Machine Learning 작업 영역에 연결하려는 경우 데이터 저장소를 만들 수 있습니다. 데이터 저장소를 만들면 작업 영역과 스토리지 간에 연결이 만들어지고 스토리지 서비스 자체가 만들어지지 않습니다. \n",
        "\n",
        "데이터 저장소를 만들고 (이미 기존) 스토리지에 연결하려면 다음을 지정해야 합니다.\n",
        "\n",
        "- 연결할 스토리지 서비스의 유형을 나타내는 클래스입니다. 아래 예제에서는 Blob Storage(`AzureBlobDatastore`)에 연결합니다.\n",
        "- `name`: Azure Machine Learning 작업 영역에 있는 데이터 저장소의 표시 이름입니다.\n",
        "- `description`: 데이터 저장소에 대한 자세한 정보를 제공하는 선택적 설명입니다.\n",
        "- `account_name`: Azure Storage 계정의 이름입니다.\n",
        "- `container_name`: Azure Storage 계정에 Blob을 저장할 컨테이너의 이름입니다.\n",
        "- `credentials`: 인증 방법 및 인증할 자격 증명을 제공합니다. 아래 예제에서는 계정 키를 사용합니다.\n",
        "\n",
        "**중요**: \n",
        "- **YOUR-STORAGE-ACCOUNT-NAME**을 자동으로 생성된 스토리지 계정의 이름으로 바꿉니다. \n",
        "- 에 대한 `account_key` **XXXX-XXXX**를 Azure Storage 계정의 계정 키로 바꿉니다. \n",
        "\n",
        "[Azure Portal](https://portal.azure.com) 이동하여 계정 키를 검색하고, 스토리지 계정으로 이동하고, **액세스 키** 탭에서 key1 또는 key2의 **키** 값을 복사할 수 있습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "데이터 저장소를 다시 나열하여 라는 `blob_training_data` 새 데이터 저장소가 만들어졌는지 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790805418
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 데이터 자산 만들기\n",
        "\n",
        "데이터 저장소의 특정 폴더 또는 파일을 가리키려면 데이터 자산을 만들 수 있습니다. 데이터 자산에는 다음 세 가지 유형이 있습니다.\n",
        "\n",
        "- `URI_FILE` 는 특정 파일을 가리킵니다.\n",
        "- `URI_FOLDER` 는 특정 폴더를 가리킵니다.\n",
        "- `MLTABLE` 는 폴더 내에서 하나 이상의 파일을 읽는 방법을 지정하는 MLTable 파일을 가리킵니다.\n",
        "\n",
        "세 가지 유형의 데이터 자산을 모두 만들어 두 자산의 차이점을 경험하게 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "데이터 자산을 만들 `URI_FILE` 려면 특정 파일을 가리키는 경로를 지정해야 합니다. 경로는 로컬 경로 또는 클라우드 경로일 수 있습니다.\n",
        "\n",
        "아래 예제에서는 *로컬* 경로를 참조하여 데이터 자산을 만듭니다. Azure Machine Learning 작업 영역에서 작업할 때 데이터를 항상 사용할 수 있도록 하려면 로컬 파일이 자동으로 기본 데이터 저장소에 업로드됩니다. 이 경우 파일은 `diabetes.csv` **workspaceblobstore** 데이터 저장소의 **LocalUpload** 폴더에 업로드됩니다. \n",
        "\n",
        "로컬 파일에서 데이터 자산을 만들려면 다음 셀을 실행합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "데이터 자산을 만들 `URI_FOLDER` 려면 특정 폴더를 가리키는 경로를 지정해야 합니다. 경로는 로컬 경로 또는 클라우드 경로일 수 있습니다.\n",
        "\n",
        "아래 예제에서는 *클라우드* 경로를 참조하여 데이터 자산을 만듭니다. 경로가 아직 존재할 필요가 없습니다. 데이터가 경로에 업로드될 때 폴더가 만들어집니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790818340
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "데이터 자산을 만들 `MLTable` 려면 MLTable 파일이 포함된 폴더를 가리키는 경로를 지정해야 합니다. 경로는 로컬 경로 또는 클라우드 경로일 수 있습니다. \n",
        "\n",
        "아래 예제에서는 MLTable 및 CSV 파일이 포함된 *로컬* 경로를 참조하여 데이터 자산을 만듭니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "새 데이터 자산이 만들어졌는지 확인하려면 작업 영역의 모든 데이터 자산을 다시 나열할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790835295
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Notebook에서 데이터 읽기\n",
        "\n",
        "처음에는 Notebook의 데이터 자산으로 작업하여 데이터를 탐색하고 기계 학습 모델을 실험할 수 있습니다. `URI_FOLDER` 또는 `URI_FILE` 형식 데이터 자산은 일반적으로 데이터를 읽는 것처럼 읽습니다. 예를 들어 데이터 자산이 가리키는 CSV 파일을 읽으려면 pandas 함수 `read_csv()`를 사용할 수 있습니다. \n",
        "\n",
        "`MLTable` 형식 데이터 자산은 스키마 및 데이터 해석 방법을 지정하는 **MLTable** 파일에서 이미 *읽습니다*. 데이터가 이미 *읽혀* 있으므로 MLTable 데이터 자산을 pandas 데이터 프레임으로 쉽게 변환할 수 있습니다. \n",
        "\n",
        "터미널에서 했던 라이브러리를 `mltable` 설치해야 합니다. 그런 다음 데이터 자산을 데이터 프레임으로 변환하고 데이터를 시각화할 수 있습니다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 작업에서 데이터 사용\n",
        "\n",
        "실험에 Notebook을 사용한 후 스크립트를 사용하여 기계 학습 모델을 학습시킬 수 있습니다. 스크립트는 작업으로 실행할 수 있으며 각 작업에 대해 입력 및 출력을 지정할 수 있습니다. \n",
        "\n",
        "**데이터 자산** 또는 **데이터 저장소 경로를** 작업의 입력 또는 출력으로 사용할 수 있습니다. \n",
        "\n",
        "아래 셀은 **src** 폴더에 **move-data.py** 스크립트를 만듭니다. 스크립트는 함수를 사용하여 입력 데이터를 읽습니다 `read_csv()` . 그런 다음 스크립트는 데이터를 출력 경로에 CSV 파일로 저장합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**move-data.py** 스크립트를 실행하는 작업을 제출하려면 아래 셀을 실행합니다. \n",
        "\n",
        "작업은 로컬 **diabetes.csv** 파일을 입력으로 가리키는 데이터 자산을 `diabetes-local`사용하도록 구성됩니다. 출력은 새 데이터 저장소 `blob_training_data`의 폴더를 가리키는 경로입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790852019
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_path = './data/diabetes.csv'\n",
        "\n",
        "my_data = Data(\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
        "    name=\"diabetes-local\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `URI_FOLDER` data asset, you have to specify a path that points to a specific folder. The path can be a local path or cloud path.\n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *cloud* path. The path doesn't have to exist yet. The folder will be created when data is uploaded to the path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666793449117
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "datastore_path = 'azureml://datastores/blob_training_data/paths/data-asset-path/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=datastore_path,\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"Data asset pointing to data-asset-path folder in datastore\",\n",
        "    name=\"diabetes-datastore-path\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `MLTable` data asset, you have to specify a path that points to a folder which contains a MLTable file. The path can be a local path or cloud path. \n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *local* path which contains an MLTable and CSV file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790884342
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "local_path = 'data/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=local_path,\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"MLTable pointing to diabetes.csv in data folder\",\n",
        "    name=\"diabetes-table\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To verify that the new data assets have been created, you can list all data assets in the workspace again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790894246
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "datasets = ml_client.data.list()\n",
        "for ds_name in datasets:\n",
        "    print(ds_name.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Read data in notebook\n",
        "\n",
        "Initially, you may want to work with data assets in notebooks, to explore the data and experiment with machine learning models. Any `URI_FILE` or `URI_FOLDER` type data assets are read as you would normally read data. For example, to read a CSV file a data asset points to, you can use the pandas function `read_csv()`. \n",
        "\n",
        "A `MLTable` type data asset is already *read* by the **MLTable** file, which specifies the schema and how to interpret the data. Since the data is already *read*, you can easily convert a MLTable data asset to a pandas dataframe. \n",
        "\n",
        "You'll need to install the `mltable` library (which you did in the terminal). Then, you can convert the data asset to a dataframe and visualize the data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666792246101
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import mltable\n",
        "\n",
        "registered_data_asset = ml_client.data.get(name='diabetes-table', version=1)\n",
        "tbl = mltable.load(f\"azureml:/{registered_data_asset.id}\")\n",
        "df = tbl.to_pandas_dataframe()\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Use data in a job\n",
        "\n",
        "After using a notebook for experimentation. You can use scripts to train machine learning models. A script can be run as a job, and for each job you can specify inputs and outputs. \n",
        "\n",
        "You can use either **data assets** or **datastore paths** as inputs or outputs of a job. \n",
        "\n",
        "The cells below creates the **move-data.py** script in the **src** folder. The script reads the input data with the `read_csv()` function. The script then stores the data as a CSV file in the output path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile $script_folder/move-data.py\n",
        "# import libraries\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.input_data)\n",
        "\n",
        "    output_df = df.to_csv((Path(args.output_datastore) / \"diabetes.csv\"), index = False)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Count the rows and print the result\n",
        "    row_count = (len(df))\n",
        "    print('Analyzing {} rows of data'.format(row_count))\n",
        "    \n",
        "    return df\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--input_data\", dest='input_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--output_datastore\", dest='output_datastore',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To submit a job that runs the **move-data.py** script, run the cell below. \n",
        "\n",
        "The job is configured to use the data asset `diabetes-local`, pointing to the local **diabetes.csv** file as input. The output is a path pointing to a folder in the new datastore `blob_training_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666794414231
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import command\n",
        "\n",
        "# configure input and output\n",
        "my_job_inputs = {\n",
        "    \"local_data\": Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-local:1\")\n",
        "}\n",
        "\n",
        "my_job_outputs = {\n",
        "    \"datastore_data\": Output(type=AssetTypes.URI_FOLDER, path=\"azureml://datastores/blob_training_data/paths/datastore-path\")\n",
        "}\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python move-data.py --input_data ${{inputs.local_data}} --output_datastore ${{outputs.datastore_data}}\",\n",
        "    inputs=my_job_inputs,\n",
        "    outputs=my_job_outputs,\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"move-diabetes-data\",\n",
        "    experiment_name=\"move-diabetes-data\"\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}