{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 스크립트를 파이프라인 작업으로 실행\n",
        "\n",
        "파이프라인을 사용하면 여러 단계를 하나의 워크플로로 그룹화할 수 있습니다. 구성 요소를 사용하여 파이프라인을 빌드할 수 있습니다. 각 구성 요소는 실행할 Python 스크립트를 반영합니다. 구성 요소는 스크립트 및 실행 방법을 지정하는 YAML 파일에 정의됩니다. \n",
        "\n",
        "## 시작하기 전에\n",
        "\n",
        "이 Notebook에서 코드를 실행하려면  **최신 버전의 azureml-ai-ml** 패키지가 필요합니다. 아래 셀의 명령을 실행하여 이 패키지가 설치되어 있는지 확인합니다.\n",
        "\n",
        "> **고**:\n",
        "> **azure-ai-ml** 패키지가 설치되지 않은 경우 를 실행 `pip install azure-ai-ml` 하여 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 작업 영역에 연결\n",
        "\n",
        "필요한 SDK 패키지를 설치했으므로 작업 영역에 연결할 수 있습니다.\n",
        "\n",
        "작업 영역에 연결하려면 식별자 매개 변수(구독 ID, 리소스 그룹 이름 및 작업 영역 이름)가 필요합니다. 리소스 그룹 이름 및 작업 영역 이름이 이미 채워져 있습니다. 명령을 완료하려면 구독 ID만 필요합니다.\n",
        "\n",
        "필요한 매개 변수를 찾으려면 Studio의 오른쪽 위에 있는 구독 및 작업 영역 이름을 클릭합니다. 오른쪽에 창이 열립니다.\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> 구독 ID를 복사하고 **YOUR-SUBSCRIPTION-ID** 를 복사한 값으로 바꿉니다. </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 스크립트 만들기\n",
        "\n",
        "다음 두 단계로 파이프라인을 빌드합니다.\n",
        "\n",
        "1. **데이터 준비**: 누락된 데이터를 수정하고 데이터를 정규화합니다.\n",
        "1. **모델 학습**: 의사 결정 트리 분류 모델을 학습합니다.\n",
        "\n",
        "다음 셀을 실행하여 **src** 폴더와 두 스크립트를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663753569264
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 구성 요소 정의\n",
        "\n",
        "구성 요소를 정의하려면 다음을 지정해야 합니다.\n",
        "\n",
        "- **메타데이터**: *이름*, *표시 이름*, *버전*, *설명*, *형식* 등 메타데이터는 구성 요소를 설명하고 관리하는 데 도움이 됩니다.\n",
        "- **인터페이스**: *입력 및* *출력.* 예를 들어 모델 학습 구성 요소는 학습 데이터와 정규화 속도를 입력으로 사용하고 학습된 모델 파일을 출력으로 생성합니다. \n",
        "- **명령, 코드 & 환경**: 구성 요소를 실행하는 *명령*, *코드* 및 *환경* 입니다. 명령은 구성 요소를 실행하는 셸 명령입니다. 코드는 일반적으로 소스 코드 디렉터리를 참조합니다. 환경은 AzureML 환경(큐레이팅 또는 사용자 지정 생성), Docker 이미지 또는 conda 환경일 수 있습니다.\n",
        "\n",
        "다음 셀을 실행하여 파이프라인 단계로 실행하려는 각 구성 요소에 대한 YAML을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 구성 요소 로드\n",
        "\n",
        "이제 각 구성 요소를 정의했으므로 YAML 파일을 참조하여 구성 요소를 로드할 수 있습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 파이프라인 빌드\n",
        "\n",
        "구성 요소를 만들고 로드한 후 파이프라인을 빌드할 수 있습니다. 두 구성 요소를 파이프라인으로 구성합니다. `prep_data` 먼저 구성 요소를 실행하려고 합니다. 첫 번째 구성 요소의 출력은 모델을 학습시키는 두 번째 구성 요소 `train_decision_tree`의 입력이어야 합니다.\n",
        "\n",
        "함수는 `diabetes_classification` 전체 파이프라인을 나타냅니다. 함수에는 하나의 입력 변수인 가 `pipeline_job_input`예상됩니다. 설정 중에 데이터 자산이 만들어졌습니다. 등록된 데이터 자산을 파이프라인 입력으로 사용합니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "개체를 인쇄하여 파이프라인 작업의 구성을 검색할 수 있습니다.`pipeline_job`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "매개 변수를 참조하고 새 값을 지정하여 파이프라인 작업 구성의 매개 변수를 변경할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 파이프라인 작업 제출\n",
        "\n",
        "마지막으로 파이프라인을 빌드하고 필요에 따라 실행되도록 파이프라인 작업을 구성한 경우 파이프라인 작업을 제출할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the components\n",
        "\n",
        "To define the component you need to specify:\n",
        "\n",
        "- **Metadata**: *name*, *display name*, *version*, *description*, *type* etc. The metadata helps to describe and manage the component.\n",
        "- **Interface**: *inputs* and *outputs*. For example, a model training component will take training data and the regularization rate as input, and generate a trained model file as output. \n",
        "- **Command, code & environment**: the *command*, *code* and *environment* to run the component. Command is the shell command to execute the component. Code usually refers to a source code directory. Environment could be an AzureML environment (curated or custom created), docker image or conda environment.\n",
        "\n",
        "Run the following cells to create a YAML for each component you want to run as a pipeline step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile prep-data.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: prep_data\n",
        "display_name: Prepare training data\n",
        "version: 1\n",
        "type: command\n",
        "inputs:\n",
        "  input_data: \n",
        "    type: uri_file\n",
        "outputs:\n",
        "  output_data:\n",
        "    type: uri_file\n",
        "code: ./src\n",
        "environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
        "command: >-\n",
        "  python prep-data.py \n",
        "  --input_data ${{inputs.input_data}}\n",
        "  --output_data ${{outputs.output_data}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile train-model.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: train_model\n",
        "display_name: Train a decision tree classifier model\n",
        "version: 1\n",
        "type: command\n",
        "inputs:\n",
        "  training_data: \n",
        "    type: uri_file\n",
        "  reg_rate:\n",
        "    type: number\n",
        "    default: 0.01\n",
        "outputs:\n",
        "  model_output:\n",
        "    type: mlflow_model\n",
        "code: ./src\n",
        "environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
        "command: >-\n",
        "  python train-model.py \n",
        "  --training_data ${{inputs.training_data}} \n",
        "  --reg_rate ${{inputs.reg_rate}} \n",
        "  --model_output ${{outputs.model_output}} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the components\n",
        "\n",
        "Now that you have defined each component, you can load the components by referring to the YAML files. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import load_component\n",
        "parent_dir = \"\"\n",
        "\n",
        "prep_data = load_component(source=parent_dir + \"./prep-data.yml\")\n",
        "train_decision_tree = load_component(source=parent_dir + \"./train-model.yml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the pipeline\n",
        "\n",
        "After creating and loading the components, you can build the pipeline. You'll compose the two components into a pipeline. First, you'll want the `prep_data` component to run. The output of the first component should be the input of the second component `train_decision_tree`, which will train the model.\n",
        "\n",
        "The `diabetes_classification` function represents the complete pipeline. The function expects one input variable: `pipeline_job_input`. A data asset was created during setup. You'll use the registered data asset as the pipeline input. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "\n",
        "@pipeline()\n",
        "def diabetes_classification(pipeline_job_input):\n",
        "    clean_data = prep_data(input_data=pipeline_job_input)\n",
        "    train_model = train_decision_tree(training_data=clean_data.outputs.output_data)\n",
        "\n",
        "    return {\n",
        "        \"pipeline_job_transformed_data\": clean_data.outputs.output_data,\n",
        "        \"pipeline_job_trained_model\": train_model.outputs.model_output,\n",
        "    }\n",
        "\n",
        "pipeline_job = diabetes_classification(Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-data:1\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can retrieve the configuration of the pipeline job by printing the `pipeline_job` object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "print(pipeline_job)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can change any parameter of the pipeline job configuration by referring to the parameter and specifying the new value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# change the output mode\n",
        "pipeline_job.outputs.pipeline_job_transformed_data.mode = \"upload\"\n",
        "pipeline_job.outputs.pipeline_job_trained_model.mode = \"upload\"\n",
        "# set pipeline level compute\n",
        "pipeline_job.settings.default_compute = \"aml-cluster\"\n",
        "# set pipeline level datastore\n",
        "pipeline_job.settings.default_datastore = \"workspaceblobstore\"\n",
        "\n",
        "# print the pipeline job again to review the changes\n",
        "print(pipeline_job)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit the pipeline job\n",
        "\n",
        "Finally, when you've built the pipeline and configured the pipeline job to run as required, you can submit the pipeline job:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# submit job to workspace\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name=\"pipeline_diabetes\"\n",
        ")\n",
        "pipeline_job"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}